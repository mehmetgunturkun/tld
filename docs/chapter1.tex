\documentclass{report}

\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{fixltx2e}
\usepackage{hyperref}

\begin{document}
    % \chapter{Introduction}
    % \label{chap:Introduction}
    %
    % \chapter{Related Work}
    % \label{chap:Related Work}

    \chapter{TLD Approach}
    \paragraph{}
        TLD implementation is based on three main modules such as: Tracker, Detector and Learner (Integrator).
        As an input, user gives a sequence of images and an initial box that contains an object of interest.
        Tracker tracks the initial box from frame to frame and Detector finds the candidate boxes containing the object. They both
        run independently and halt with possible individual errors. However, Integrator
        evaluate two separate results from Tracker and Detector, validates tracked box, combines with detected boxes
        and generates a reasonable result.
        Besides, it sends feedback to Detector in order to rule out false positives
        and false negatives if necessary to make model more robust.
        With this approach, it eliminates tracker's shift error by validation from Detector and uses Tracker
        to make Detector learn new instances of object and avoid misclassification in further frames and .
        This is why as long as the TLD tracks the object, learns more and more about it.
    \section{Tracker}
        \paragraph{}
            Tracker, takes two consequtive frames (frame\textsubscript{0}, frame\textsubscript{1})
            and a bounding box (box\textsubscript{0}), containing the target object within frame\textsubscript{0}.
            Tracker's main task is to estimate the location of the bounding box in the second frame (box\textsubscript{0})
            or to decide whether the target object is still visible. Basically, tracker generates points in the given
            bounding box, tracks each point from first frame to second frame, filter the reliable ones and estimates
            the displacement of the box with these points.
        \paragraph{Point Generation}
            In order to generate points in the given box, we divide the box into equal
            parts in both directions: x and y. Every corner that horizontal and vertical stripes meet, we generate
            new point. For example if we divide the box into m parts horizontally and n parts vertically, as a result,
            we have \textit{mxn} points
        \paragraph{Point Tracking}
            TLD uses Pyramidal Lucas-Kanade tracker, which is already implemented in OpenCV, to track points from frame
            to frame. However, Lucas-Kanade Tracker, tracks the points only in one direction. To be more robust,
            we track backward either and calculate the forward-backward error.
            \begin{gather}
                track(frame_{0}, frame_{1}, point_{0}) = point_{1} \\
                track(frame_{1}, frame_{0}, point_{1}) = point_{0}' \\
                fb_{error} = euclidianDistance(point_{0}, point_{0}')
            \end{gather}
        \paragraph{Filtering Reliable Points}
            At this stage of tracking, we have tracked points with forward-backward error
            for each \textit{point to point correspondences}. Besides, forward-backward error, we compute
            Nearest Normalized Correlation(NCC) for each correspondences as an additional metric for filtering.

            With these metrics, we compute median value for forward-backward errors and NCC values, and filter out
            the correspondences that has larger fb\textsubscript{error} value than median\textsubscript{fbError} and
            lower NCC value than median\textsubscript{NCC}.

        \paragraph{Relocation of Box}
            At the end of the tracking process, we have points and relatively robust displacements for each of them.
            With these displacements, we, again, get the median value of displacements in two direction and translate
            the bounding box with these values as follows:

            \begin{gather}
                box_{0} = box(x_{0}, y_{0}, width_{0}, height_{0}) \\
                box_{1} = box(x_{0} + \Delta x, y_{0} + \Delta y, width_{0}, height_{0})
            \end{gather}
    \section{Detector}
        \paragraph{}
            Detector's main job is to identify candidate boxes that possibly contain the object. In order to find
            object instance(s) in the given frame, initially, detector generates boxes by sliding window in different sizes,
            along the image. After that, for each box, it is need to be decided whether there is an instance of the object or not.
            This part of the process is basically a classification problem. Detector solves this problem in those stages:
            \textbf{Variance Classifier}, \textbf{Ensemble Classifier} and \textbf{Nearest Neighbour Classifier}.

        \paragraph{Variance Classifier}
            is, computationally and logically, the simplest stage along the process.
            For given box, it computes the variance of the pixel's intensity values which are inside of the box and
            compares the variance value to the initial box. If the variance\textsubscript{box} is less than half of the
            variance\textsubscript{initial box} then it is eliminated. This process eliminates the boxes from background, so that
            computationally more complex proceses are not going to applied these patches.

        \paragraph{Ensemble Classifier} is the second classifier in the detection process. It has
            \emph{n} base classifiers which store \emph{m} horizontal and vertical pixel comparisons.
            Every base classifier make these comparisons and for each comparison it outputs a bit: 1 or 0
            whether first pixel has higher value than the second.
            \textbf{As a result of all comparisons, on one box, we have an array of bits which has \emph{m} elements.
            Every base classifier stores how many positive and negative boxes which has generated same array of bits.}

        \paragraph{Nearest Neighbor Classifier} is the last and, computationally, most intensive stage in the process.
            An object model, which is simply two lists of bounding boxes that are labelled as positive and negative, is stored
            within this classifier. When new box come to be classified, it compares the sample with all
            boxes in positive and negative list and takes the highest normalized cross correlation value from both lists.
            Divides them and if the score is higher than threshold then sample is classified as positive,
            otherwise it is eliminated.
    \section{Integrator (Learner)}
        \paragraph{}
            Simply, Integrator takes the output of both component Tracker and Detector as input, validates, combines
            and generates refined result. These discrete modules already have its own failure reasons
            and peculiar errors like tracker can shift away from the object, detector also can misclassify some other objects. This is
            where Integrator step in. It verifies tracker's result by detector. If the box that tracker produced is correlated with the object model
            then it filters and refines the boxes that detector generated according to the tracker's result.

            In the light of this brief introduction for learner modules there are four possible situations that integrator should cover:
            \begin{enumerate}
                \item Tracker cannot track the box or it is not validated and, also, Detector failed to detect.
                    In this case there is nothing much to proceed, so Integrator simply returns no box as a result.
                \item Tracker cannot track the box or it is not validated; however, Detector marked some boxes as candidates.
                    We have some boxes that we might move on processing sequence, so TLD checks the boxes and if there is only one
                    box as detected then re-initializes the tracker and move to next frame. The reason for one box rule, actually,
                    we do not have additional information to select one of the boxes.
                \item Tracker tracked the box or it is validated; however, Detector cannot find any instance in image.
                    This case indicates that detector has not learnt this part of the object yet, or there might be some
                    partial occlusion, brightness changes, etc so we update the object model with the tracked box.
                \item Tracker tracked the box or it is valid and Detector finds some boxes as instance of the object.
                    In final case, both modules generated some result and we need to refined them. Initially, we check that there is one
                    and only one box that has higher NCC score than the tracker's result. If there is a box that meets these conditions
                    then we re-initialize the tracker with that box and move to next frame.

                    However, if there is box further away from the tracked box and has lower \textbf{similarity???} then this means that
                    detector misclassified some boxes. To avoid these misclassifications in future images and
                    make the object model more stable, we set labels of these misclassified boxes to negative,
                    tracked box as positive and update the object model with this training set.
            \end{enumerate}
\end{document}
